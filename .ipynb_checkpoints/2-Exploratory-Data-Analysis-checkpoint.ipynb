{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data cleaning step where we put our data into a few standard formats, the next step is to take a look at the data and see if what we're looking at makes sense. Before applying any fancy algorithms, it's always important to explore the data first.\n",
    "\n",
    "When working with numerical data, some of the exploratory data analysis (EDA) techniques we can use include finding the average of the data set, the distribution of the data, the most common values, etc. The idea is the same when working with text data. We are going to find some more obvious patterns with EDA before identifying the hidden patterns with machines learning (ML) techniques. We are going to look at the following for each comedian:\n",
    "\n",
    "1. **Most common words** - find these and create word clouds\n",
    "2. **Size of vocabulary** - look number of unique words and also how quickly someone speaks\n",
    "3. **Amount of profanity** - most common terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Common Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ali</th>\n",
       "      <th>anthony</th>\n",
       "      <th>bill</th>\n",
       "      <th>bo</th>\n",
       "      <th>dave</th>\n",
       "      <th>hasan</th>\n",
       "      <th>jim</th>\n",
       "      <th>joe</th>\n",
       "      <th>john</th>\n",
       "      <th>louis</th>\n",
       "      <th>mike</th>\n",
       "      <th>ricky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaaaah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaahhhhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaauuugghhhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaahhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ali  anthony  bill  bo  dave  hasan  jim  joe  john  louis  \\\n",
       "aaaaah              0        0     1   0     0      0    0    0     0      0   \n",
       "aaaaahhhhhhh        0        0     0   1     0      0    0    0     0      0   \n",
       "aaaaauuugghhhhhh    0        0     0   1     0      0    0    0     0      0   \n",
       "aaaahhhhh           0        0     0   1     0      0    0    0     0      0   \n",
       "aaah                0        0     0   0     1      0    0    0     0      0   \n",
       "\n",
       "                  mike  ricky  \n",
       "aaaaah               0      0  \n",
       "aaaaahhhhhhh         0      0  \n",
       "aaaaauuugghhhhhh     0      0  \n",
       "aaaahhhhh            0      0  \n",
       "aaah                 0      0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the document-term matrix\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle('dtm.pkl')\n",
    "data = data.transpose()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ali': [('like', 126),\n",
       "  ('im', 74),\n",
       "  ('know', 65),\n",
       "  ('just', 64),\n",
       "  ('dont', 61),\n",
       "  ('shit', 34),\n",
       "  ('thats', 34),\n",
       "  ('youre', 31),\n",
       "  ('gonna', 28),\n",
       "  ('ok', 26),\n",
       "  ('lot', 24),\n",
       "  ('wanna', 21),\n",
       "  ('gotta', 21),\n",
       "  ('oh', 21),\n",
       "  ('husband', 20),\n",
       "  ('got', 19),\n",
       "  ('right', 19),\n",
       "  ('time', 19),\n",
       "  ('cause', 18),\n",
       "  ('women', 17),\n",
       "  ('day', 17),\n",
       "  ('people', 16),\n",
       "  ('pregnant', 15),\n",
       "  ('need', 14),\n",
       "  ('god', 14),\n",
       "  ('hes', 14),\n",
       "  ('tell', 13),\n",
       "  ('yeah', 13),\n",
       "  ('theyre', 12),\n",
       "  ('dude', 12)],\n",
       " 'anthony': [('im', 60),\n",
       "  ('like', 50),\n",
       "  ('know', 39),\n",
       "  ('dont', 38),\n",
       "  ('joke', 34),\n",
       "  ('got', 34),\n",
       "  ('thats', 31),\n",
       "  ('said', 31),\n",
       "  ('anthony', 27),\n",
       "  ('day', 26),\n",
       "  ('say', 26),\n",
       "  ('just', 26),\n",
       "  ('guys', 23),\n",
       "  ('people', 22),\n",
       "  ('tell', 19),\n",
       "  ('youre', 19),\n",
       "  ('right', 18),\n",
       "  ('grandma', 18),\n",
       "  ('time', 17),\n",
       "  ('think', 17),\n",
       "  ('thing', 17),\n",
       "  ('yeah', 16),\n",
       "  ('jokes', 16),\n",
       "  ('school', 16),\n",
       "  ('good', 16),\n",
       "  ('did', 16),\n",
       "  ('gonna', 15),\n",
       "  ('okay', 15),\n",
       "  ('ive', 15),\n",
       "  ('baby', 15)],\n",
       " 'bill': [('like', 200),\n",
       "  ('just', 149),\n",
       "  ('right', 131),\n",
       "  ('im', 107),\n",
       "  ('know', 99),\n",
       "  ('dont', 95),\n",
       "  ('gonna', 77),\n",
       "  ('got', 72),\n",
       "  ('fucking', 70),\n",
       "  ('yeah', 67),\n",
       "  ('shit', 63),\n",
       "  ('youre', 59),\n",
       "  ('thats', 56),\n",
       "  ('dude', 40),\n",
       "  ('think', 36),\n",
       "  ('want', 36),\n",
       "  ('fuck', 36),\n",
       "  ('people', 32),\n",
       "  ('did', 31),\n",
       "  ('hes', 31),\n",
       "  ('guy', 30),\n",
       "  ('didnt', 29),\n",
       "  ('make', 28),\n",
       "  ('come', 27),\n",
       "  ('thing', 26),\n",
       "  ('going', 26),\n",
       "  ('theyre', 25),\n",
       "  ('let', 24),\n",
       "  ('theres', 24),\n",
       "  ('little', 23)],\n",
       " 'bo': [('know', 50),\n",
       "  ('like', 44),\n",
       "  ('think', 37),\n",
       "  ('im', 37),\n",
       "  ('love', 37),\n",
       "  ('bo', 35),\n",
       "  ('just', 35),\n",
       "  ('stuff', 33),\n",
       "  ('repeat', 31),\n",
       "  ('dont', 29),\n",
       "  ('yeah', 27),\n",
       "  ('want', 25),\n",
       "  ('right', 24),\n",
       "  ('cos', 23),\n",
       "  ('people', 22),\n",
       "  ('said', 22),\n",
       "  ('eye', 22),\n",
       "  ('fucking', 22),\n",
       "  ('contact', 21),\n",
       "  ('um', 21),\n",
       "  ('prolonged', 21),\n",
       "  ('youre', 19),\n",
       "  ('thats', 19),\n",
       "  ('time', 18),\n",
       "  ('good', 17),\n",
       "  ('little', 17),\n",
       "  ('sluts', 17),\n",
       "  ('man', 17),\n",
       "  ('oh', 15),\n",
       "  ('fuck', 15)],\n",
       " 'dave': [('like', 103),\n",
       "  ('know', 79),\n",
       "  ('said', 63),\n",
       "  ('just', 61),\n",
       "  ('im', 47),\n",
       "  ('shit', 45),\n",
       "  ('people', 43),\n",
       "  ('didnt', 39),\n",
       "  ('ahah', 38),\n",
       "  ('dont', 38),\n",
       "  ('time', 36),\n",
       "  ('thats', 33),\n",
       "  ('fuck', 33),\n",
       "  ('fucking', 32),\n",
       "  ('black', 31),\n",
       "  ('man', 30),\n",
       "  ('good', 27),\n",
       "  ('got', 27),\n",
       "  ('right', 22),\n",
       "  ('gonna', 21),\n",
       "  ('gay', 20),\n",
       "  ('lot', 20),\n",
       "  ('nigga', 20),\n",
       "  ('hes', 19),\n",
       "  ('did', 19),\n",
       "  ('yeah', 18),\n",
       "  ('oj', 18),\n",
       "  ('oh', 18),\n",
       "  ('come', 17),\n",
       "  ('guys', 16)],\n",
       " 'hasan': [('like', 220),\n",
       "  ('im', 136),\n",
       "  ('know', 70),\n",
       "  ('dont', 64),\n",
       "  ('dad', 59),\n",
       "  ('youre', 51),\n",
       "  ('just', 46),\n",
       "  ('going', 41),\n",
       "  ('thats', 39),\n",
       "  ('want', 38),\n",
       "  ('got', 35),\n",
       "  ('love', 34),\n",
       "  ('shes', 32),\n",
       "  ('hasan', 31),\n",
       "  ('say', 30),\n",
       "  ('right', 30),\n",
       "  ('time', 27),\n",
       "  ('life', 25),\n",
       "  ('mom', 25),\n",
       "  ('people', 25),\n",
       "  ('hey', 24),\n",
       "  ('oh', 24),\n",
       "  ('look', 22),\n",
       "  ('did', 22),\n",
       "  ('brown', 21),\n",
       "  ('parents', 20),\n",
       "  ('guys', 20),\n",
       "  ('white', 20),\n",
       "  ('girl', 19),\n",
       "  ('whats', 19)],\n",
       " 'jim': [('like', 108),\n",
       "  ('im', 101),\n",
       "  ('dont', 90),\n",
       "  ('right', 81),\n",
       "  ('fucking', 78),\n",
       "  ('know', 63),\n",
       "  ('just', 63),\n",
       "  ('went', 63),\n",
       "  ('youre', 48),\n",
       "  ('people', 44),\n",
       "  ('thats', 42),\n",
       "  ('day', 40),\n",
       "  ('oh', 40),\n",
       "  ('think', 39),\n",
       "  ('going', 39),\n",
       "  ('fuck', 37),\n",
       "  ('thing', 34),\n",
       "  ('goes', 34),\n",
       "  ('said', 32),\n",
       "  ('guns', 30),\n",
       "  ('theyre', 29),\n",
       "  ('good', 28),\n",
       "  ('ive', 27),\n",
       "  ('theres', 26),\n",
       "  ('women', 26),\n",
       "  ('cause', 26),\n",
       "  ('got', 26),\n",
       "  ('want', 25),\n",
       "  ('really', 23),\n",
       "  ('hes', 23)],\n",
       " 'joe': [('like', 143),\n",
       "  ('people', 100),\n",
       "  ('just', 87),\n",
       "  ('dont', 79),\n",
       "  ('fucking', 69),\n",
       "  ('im', 69),\n",
       "  ('fuck', 66),\n",
       "  ('thats', 62),\n",
       "  ('gonna', 52),\n",
       "  ('theyre', 49),\n",
       "  ('know', 46),\n",
       "  ('youre', 42),\n",
       "  ('think', 41),\n",
       "  ('shit', 40),\n",
       "  ('got', 36),\n",
       "  ('theres', 34),\n",
       "  ('right', 31),\n",
       "  ('man', 30),\n",
       "  ('house', 27),\n",
       "  ('oh', 25),\n",
       "  ('kids', 25),\n",
       "  ('white', 24),\n",
       "  ('cause', 24),\n",
       "  ('say', 23),\n",
       "  ('real', 22),\n",
       "  ('life', 21),\n",
       "  ('time', 20),\n",
       "  ('really', 20),\n",
       "  ('gotta', 20),\n",
       "  ('dude', 20)],\n",
       " 'john': [('like', 190),\n",
       "  ('know', 66),\n",
       "  ('just', 53),\n",
       "  ('dont', 52),\n",
       "  ('said', 39),\n",
       "  ('clinton', 34),\n",
       "  ('im', 33),\n",
       "  ('thats', 31),\n",
       "  ('right', 29),\n",
       "  ('youre', 28),\n",
       "  ('little', 26),\n",
       "  ('hey', 25),\n",
       "  ('got', 24),\n",
       "  ('time', 24),\n",
       "  ('people', 22),\n",
       "  ('say', 22),\n",
       "  ('cause', 22),\n",
       "  ('mom', 22),\n",
       "  ('think', 21),\n",
       "  ('way', 21),\n",
       "  ('day', 21),\n",
       "  ('old', 21),\n",
       "  ('oh', 21),\n",
       "  ('gonna', 21),\n",
       "  ('cow', 20),\n",
       "  ('went', 18),\n",
       "  ('wife', 18),\n",
       "  ('really', 18),\n",
       "  ('dad', 17),\n",
       "  ('real', 17)],\n",
       " 'louis': [('like', 110),\n",
       "  ('just', 97),\n",
       "  ('know', 70),\n",
       "  ('dont', 53),\n",
       "  ('thats', 51),\n",
       "  ('im', 50),\n",
       "  ('youre', 50),\n",
       "  ('life', 41),\n",
       "  ('people', 40),\n",
       "  ('thing', 31),\n",
       "  ('gonna', 29),\n",
       "  ('hes', 29),\n",
       "  ('cause', 28),\n",
       "  ('theres', 28),\n",
       "  ('shit', 25),\n",
       "  ('time', 22),\n",
       "  ('good', 22),\n",
       "  ('tit', 22),\n",
       "  ('right', 21),\n",
       "  ('think', 21),\n",
       "  ('theyre', 21),\n",
       "  ('really', 20),\n",
       "  ('course', 19),\n",
       "  ('kids', 18),\n",
       "  ('murder', 18),\n",
       "  ('guy', 18),\n",
       "  ('ok', 17),\n",
       "  ('mean', 15),\n",
       "  ('fuck', 15),\n",
       "  ('didnt', 15)],\n",
       " 'mike': [('like', 234),\n",
       "  ('im', 142),\n",
       "  ('know', 105),\n",
       "  ('said', 88),\n",
       "  ('just', 83),\n",
       "  ('dont', 76),\n",
       "  ('think', 51),\n",
       "  ('thats', 51),\n",
       "  ('says', 46),\n",
       "  ('cause', 35),\n",
       "  ('right', 34),\n",
       "  ('jenny', 33),\n",
       "  ('goes', 32),\n",
       "  ('id', 30),\n",
       "  ('really', 30),\n",
       "  ('point', 28),\n",
       "  ('youre', 28),\n",
       "  ('mean', 28),\n",
       "  ('gonna', 27),\n",
       "  ('got', 25),\n",
       "  ('yeah', 25),\n",
       "  ('people', 23),\n",
       "  ('kind', 23),\n",
       "  ('uh', 22),\n",
       "  ('say', 21),\n",
       "  ('feel', 20),\n",
       "  ('want', 19),\n",
       "  ('didnt', 19),\n",
       "  ('going', 19),\n",
       "  ('time', 19)],\n",
       " 'ricky': [('right', 110),\n",
       "  ('like', 80),\n",
       "  ('just', 66),\n",
       "  ('im', 66),\n",
       "  ('dont', 56),\n",
       "  ('know', 55),\n",
       "  ('said', 51),\n",
       "  ('yeah', 49),\n",
       "  ('fucking', 47),\n",
       "  ('got', 44),\n",
       "  ('say', 43),\n",
       "  ('youre', 41),\n",
       "  ('went', 40),\n",
       "  ('id', 39),\n",
       "  ('thats', 38),\n",
       "  ('people', 34),\n",
       "  ('didnt', 33),\n",
       "  ('little', 32),\n",
       "  ('joke', 31),\n",
       "  ('theyre', 29),\n",
       "  ('hes', 29),\n",
       "  ('ive', 28),\n",
       "  ('thing', 26),\n",
       "  ('going', 26),\n",
       "  ('years', 24),\n",
       "  ('day', 23),\n",
       "  ('saying', 22),\n",
       "  ('theres', 22),\n",
       "  ('ill', 21),\n",
       "  ('big', 21)]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the top 30 words said by each comedian\n",
    "top_dict = {}\n",
    "for c in data.columns:\n",
    "    top = data[c].sort_values(ascending=False).head(30)\n",
    "    top_dict[c]= list(zip(top.index, top.values))\n",
    "\n",
    "top_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ali\n",
      "like, im, know, just, dont, shit, thats, youre, gonna, ok, lot, wanna, gotta, oh\n",
      "---\n",
      "anthony\n",
      "im, like, know, dont, joke, got, thats, said, anthony, day, say, just, guys, people\n",
      "---\n",
      "bill\n",
      "like, just, right, im, know, dont, gonna, got, fucking, yeah, shit, youre, thats, dude\n",
      "---\n",
      "bo\n",
      "know, like, think, im, love, bo, just, stuff, repeat, dont, yeah, want, right, cos\n",
      "---\n",
      "dave\n",
      "like, know, said, just, im, shit, people, didnt, ahah, dont, time, thats, fuck, fucking\n",
      "---\n",
      "hasan\n",
      "like, im, know, dont, dad, youre, just, going, thats, want, got, love, shes, hasan\n",
      "---\n",
      "jim\n",
      "like, im, dont, right, fucking, know, just, went, youre, people, thats, day, oh, think\n",
      "---\n",
      "joe\n",
      "like, people, just, dont, fucking, im, fuck, thats, gonna, theyre, know, youre, think, shit\n",
      "---\n",
      "john\n",
      "like, know, just, dont, said, clinton, im, thats, right, youre, little, hey, got, time\n",
      "---\n",
      "louis\n",
      "like, just, know, dont, thats, im, youre, life, people, thing, gonna, hes, cause, theres\n",
      "---\n",
      "mike\n",
      "like, im, know, said, just, dont, think, thats, says, cause, right, jenny, goes, id\n",
      "---\n",
      "ricky\n",
      "right, like, just, im, dont, know, said, yeah, fucking, got, say, youre, went, id\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Print the top 15 words said by each comedian\n",
    "for comedian, top_words in top_dict.items():\n",
    "    print(comedian)\n",
    "    print(', '.join([word for word, count in top_words[0:14]]))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** At this point, we could go on and create word clouds. However, by looking at these top words, you can see that some of them have very little meaning and could be added to a stop words list, so let's do just that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like',\n",
       " 'im',\n",
       " 'know',\n",
       " 'just',\n",
       " 'dont',\n",
       " 'shit',\n",
       " 'thats',\n",
       " 'youre',\n",
       " 'gonna',\n",
       " 'ok',\n",
       " 'lot',\n",
       " 'wanna',\n",
       " 'gotta',\n",
       " 'oh',\n",
       " 'husband',\n",
       " 'got',\n",
       " 'right',\n",
       " 'time',\n",
       " 'cause',\n",
       " 'women',\n",
       " 'day',\n",
       " 'people',\n",
       " 'pregnant',\n",
       " 'need',\n",
       " 'god',\n",
       " 'hes',\n",
       " 'tell',\n",
       " 'yeah',\n",
       " 'theyre',\n",
       " 'dude',\n",
       " 'im',\n",
       " 'like',\n",
       " 'know',\n",
       " 'dont',\n",
       " 'joke',\n",
       " 'got',\n",
       " 'thats',\n",
       " 'said',\n",
       " 'anthony',\n",
       " 'day',\n",
       " 'say',\n",
       " 'just',\n",
       " 'guys',\n",
       " 'people',\n",
       " 'tell',\n",
       " 'youre',\n",
       " 'right',\n",
       " 'grandma',\n",
       " 'time',\n",
       " 'think',\n",
       " 'thing',\n",
       " 'yeah',\n",
       " 'jokes',\n",
       " 'school',\n",
       " 'good',\n",
       " 'did',\n",
       " 'gonna',\n",
       " 'okay',\n",
       " 'ive',\n",
       " 'baby',\n",
       " 'like',\n",
       " 'just',\n",
       " 'right',\n",
       " 'im',\n",
       " 'know',\n",
       " 'dont',\n",
       " 'gonna',\n",
       " 'got',\n",
       " 'fucking',\n",
       " 'yeah',\n",
       " 'shit',\n",
       " 'youre',\n",
       " 'thats',\n",
       " 'dude',\n",
       " 'think',\n",
       " 'want',\n",
       " 'fuck',\n",
       " 'people',\n",
       " 'did',\n",
       " 'hes',\n",
       " 'guy',\n",
       " 'didnt',\n",
       " 'make',\n",
       " 'come',\n",
       " 'thing',\n",
       " 'going',\n",
       " 'theyre',\n",
       " 'let',\n",
       " 'theres',\n",
       " 'little',\n",
       " 'know',\n",
       " 'like',\n",
       " 'think',\n",
       " 'im',\n",
       " 'love',\n",
       " 'bo',\n",
       " 'just',\n",
       " 'stuff',\n",
       " 'repeat',\n",
       " 'dont',\n",
       " 'yeah',\n",
       " 'want',\n",
       " 'right',\n",
       " 'cos',\n",
       " 'people',\n",
       " 'said',\n",
       " 'eye',\n",
       " 'fucking',\n",
       " 'contact',\n",
       " 'um',\n",
       " 'prolonged',\n",
       " 'youre',\n",
       " 'thats',\n",
       " 'time',\n",
       " 'good',\n",
       " 'little',\n",
       " 'sluts',\n",
       " 'man',\n",
       " 'oh',\n",
       " 'fuck',\n",
       " 'like',\n",
       " 'know',\n",
       " 'said',\n",
       " 'just',\n",
       " 'im',\n",
       " 'shit',\n",
       " 'people',\n",
       " 'didnt',\n",
       " 'ahah',\n",
       " 'dont',\n",
       " 'time',\n",
       " 'thats',\n",
       " 'fuck',\n",
       " 'fucking',\n",
       " 'black',\n",
       " 'man',\n",
       " 'good',\n",
       " 'got',\n",
       " 'right',\n",
       " 'gonna',\n",
       " 'gay',\n",
       " 'lot',\n",
       " 'nigga',\n",
       " 'hes',\n",
       " 'did',\n",
       " 'yeah',\n",
       " 'oj',\n",
       " 'oh',\n",
       " 'come',\n",
       " 'guys',\n",
       " 'like',\n",
       " 'im',\n",
       " 'know',\n",
       " 'dont',\n",
       " 'dad',\n",
       " 'youre',\n",
       " 'just',\n",
       " 'going',\n",
       " 'thats',\n",
       " 'want',\n",
       " 'got',\n",
       " 'love',\n",
       " 'shes',\n",
       " 'hasan',\n",
       " 'say',\n",
       " 'right',\n",
       " 'time',\n",
       " 'life',\n",
       " 'mom',\n",
       " 'people',\n",
       " 'hey',\n",
       " 'oh',\n",
       " 'look',\n",
       " 'did',\n",
       " 'brown',\n",
       " 'parents',\n",
       " 'guys',\n",
       " 'white',\n",
       " 'girl',\n",
       " 'whats',\n",
       " 'like',\n",
       " 'im',\n",
       " 'dont',\n",
       " 'right',\n",
       " 'fucking',\n",
       " 'know',\n",
       " 'just',\n",
       " 'went',\n",
       " 'youre',\n",
       " 'people',\n",
       " 'thats',\n",
       " 'day',\n",
       " 'oh',\n",
       " 'think',\n",
       " 'going',\n",
       " 'fuck',\n",
       " 'thing',\n",
       " 'goes',\n",
       " 'said',\n",
       " 'guns',\n",
       " 'theyre',\n",
       " 'good',\n",
       " 'ive',\n",
       " 'theres',\n",
       " 'women',\n",
       " 'cause',\n",
       " 'got',\n",
       " 'want',\n",
       " 'really',\n",
       " 'hes',\n",
       " 'like',\n",
       " 'people',\n",
       " 'just',\n",
       " 'dont',\n",
       " 'fucking',\n",
       " 'im',\n",
       " 'fuck',\n",
       " 'thats',\n",
       " 'gonna',\n",
       " 'theyre',\n",
       " 'know',\n",
       " 'youre',\n",
       " 'think',\n",
       " 'shit',\n",
       " 'got',\n",
       " 'theres',\n",
       " 'right',\n",
       " 'man',\n",
       " 'house',\n",
       " 'oh',\n",
       " 'kids',\n",
       " 'white',\n",
       " 'cause',\n",
       " 'say',\n",
       " 'real',\n",
       " 'life',\n",
       " 'time',\n",
       " 'really',\n",
       " 'gotta',\n",
       " 'dude',\n",
       " 'like',\n",
       " 'know',\n",
       " 'just',\n",
       " 'dont',\n",
       " 'said',\n",
       " 'clinton',\n",
       " 'im',\n",
       " 'thats',\n",
       " 'right',\n",
       " 'youre',\n",
       " 'little',\n",
       " 'hey',\n",
       " 'got',\n",
       " 'time',\n",
       " 'people',\n",
       " 'say',\n",
       " 'cause',\n",
       " 'mom',\n",
       " 'think',\n",
       " 'way',\n",
       " 'day',\n",
       " 'old',\n",
       " 'oh',\n",
       " 'gonna',\n",
       " 'cow',\n",
       " 'went',\n",
       " 'wife',\n",
       " 'really',\n",
       " 'dad',\n",
       " 'real',\n",
       " 'like',\n",
       " 'just',\n",
       " 'know',\n",
       " 'dont',\n",
       " 'thats',\n",
       " 'im',\n",
       " 'youre',\n",
       " 'life',\n",
       " 'people',\n",
       " 'thing',\n",
       " 'gonna',\n",
       " 'hes',\n",
       " 'cause',\n",
       " 'theres',\n",
       " 'shit',\n",
       " 'time',\n",
       " 'good',\n",
       " 'tit',\n",
       " 'right',\n",
       " 'think',\n",
       " 'theyre',\n",
       " 'really',\n",
       " 'course',\n",
       " 'kids',\n",
       " 'murder',\n",
       " 'guy',\n",
       " 'ok',\n",
       " 'mean',\n",
       " 'fuck',\n",
       " 'didnt',\n",
       " 'like',\n",
       " 'im',\n",
       " 'know',\n",
       " 'said',\n",
       " 'just',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'thats',\n",
       " 'says',\n",
       " 'cause',\n",
       " 'right',\n",
       " 'jenny',\n",
       " 'goes',\n",
       " 'id',\n",
       " 'really',\n",
       " 'point',\n",
       " 'youre',\n",
       " 'mean',\n",
       " 'gonna',\n",
       " 'got',\n",
       " 'yeah',\n",
       " 'people',\n",
       " 'kind',\n",
       " 'uh',\n",
       " 'say',\n",
       " 'feel',\n",
       " 'want',\n",
       " 'didnt',\n",
       " 'going',\n",
       " 'time',\n",
       " 'right',\n",
       " 'like',\n",
       " 'just',\n",
       " 'im',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'said',\n",
       " 'yeah',\n",
       " 'fucking',\n",
       " 'got',\n",
       " 'say',\n",
       " 'youre',\n",
       " 'went',\n",
       " 'id',\n",
       " 'thats',\n",
       " 'people',\n",
       " 'didnt',\n",
       " 'little',\n",
       " 'joke',\n",
       " 'theyre',\n",
       " 'hes',\n",
       " 'ive',\n",
       " 'thing',\n",
       " 'going',\n",
       " 'years',\n",
       " 'day',\n",
       " 'saying',\n",
       " 'theres',\n",
       " 'ill',\n",
       " 'big']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the most common top words --> add them to the stop word list\n",
    "from collections import Counter\n",
    "\n",
    "# Let's first pull out the top 30 words for each comedian\n",
    "words = []\n",
    "for comedian in data.columns:\n",
    "    top = [word for (word, count) in top_dict[comedian]]\n",
    "    for t in top:\n",
    "        words.append(t)\n",
    "        \n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 12),\n",
       " ('im', 12),\n",
       " ('know', 12),\n",
       " ('just', 12),\n",
       " ('dont', 12),\n",
       " ('thats', 12),\n",
       " ('right', 12),\n",
       " ('people', 12),\n",
       " ('youre', 11),\n",
       " ('got', 10),\n",
       " ('time', 9),\n",
       " ('gonna', 8),\n",
       " ('think', 8),\n",
       " ('oh', 7),\n",
       " ('yeah', 7),\n",
       " ('said', 7),\n",
       " ('cause', 6),\n",
       " ('hes', 6),\n",
       " ('theyre', 6),\n",
       " ('say', 6),\n",
       " ('fucking', 6),\n",
       " ('fuck', 6),\n",
       " ('shit', 5),\n",
       " ('day', 5),\n",
       " ('thing', 5),\n",
       " ('good', 5),\n",
       " ('want', 5),\n",
       " ('didnt', 5),\n",
       " ('going', 5),\n",
       " ('theres', 5),\n",
       " ('really', 5),\n",
       " ('did', 4),\n",
       " ('little', 4),\n",
       " ('dude', 3),\n",
       " ('guys', 3),\n",
       " ('ive', 3),\n",
       " ('man', 3),\n",
       " ('life', 3),\n",
       " ('went', 3),\n",
       " ('ok', 2),\n",
       " ('lot', 2),\n",
       " ('gotta', 2),\n",
       " ('women', 2),\n",
       " ('tell', 2),\n",
       " ('joke', 2),\n",
       " ('guy', 2),\n",
       " ('come', 2),\n",
       " ('love', 2),\n",
       " ('dad', 2),\n",
       " ('mom', 2),\n",
       " ('hey', 2),\n",
       " ('white', 2),\n",
       " ('goes', 2),\n",
       " ('kids', 2),\n",
       " ('real', 2),\n",
       " ('mean', 2),\n",
       " ('id', 2),\n",
       " ('wanna', 1),\n",
       " ('husband', 1),\n",
       " ('pregnant', 1),\n",
       " ('need', 1),\n",
       " ('god', 1),\n",
       " ('anthony', 1),\n",
       " ('grandma', 1),\n",
       " ('jokes', 1),\n",
       " ('school', 1),\n",
       " ('okay', 1),\n",
       " ('baby', 1),\n",
       " ('make', 1),\n",
       " ('let', 1),\n",
       " ('bo', 1),\n",
       " ('stuff', 1),\n",
       " ('repeat', 1),\n",
       " ('cos', 1),\n",
       " ('eye', 1),\n",
       " ('contact', 1),\n",
       " ('um', 1),\n",
       " ('prolonged', 1),\n",
       " ('sluts', 1),\n",
       " ('ahah', 1),\n",
       " ('black', 1),\n",
       " ('gay', 1),\n",
       " ('nigga', 1),\n",
       " ('oj', 1),\n",
       " ('shes', 1),\n",
       " ('hasan', 1),\n",
       " ('look', 1),\n",
       " ('brown', 1),\n",
       " ('parents', 1),\n",
       " ('girl', 1),\n",
       " ('whats', 1),\n",
       " ('guns', 1),\n",
       " ('house', 1),\n",
       " ('clinton', 1),\n",
       " ('way', 1),\n",
       " ('old', 1),\n",
       " ('cow', 1),\n",
       " ('wife', 1),\n",
       " ('tit', 1),\n",
       " ('course', 1),\n",
       " ('murder', 1),\n",
       " ('says', 1),\n",
       " ('jenny', 1),\n",
       " ('point', 1),\n",
       " ('kind', 1),\n",
       " ('uh', 1),\n",
       " ('feel', 1),\n",
       " ('years', 1),\n",
       " ('saying', 1),\n",
       " ('ill', 1),\n",
       " ('big', 1)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's aggregate this list and identify the most common words along with how many routines they occur in\n",
    "Counter(words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['like',\n",
       " 'im',\n",
       " 'know',\n",
       " 'just',\n",
       " 'dont',\n",
       " 'thats',\n",
       " 'right',\n",
       " 'people',\n",
       " 'youre',\n",
       " 'got',\n",
       " 'time',\n",
       " 'gonna',\n",
       " 'think',\n",
       " 'oh',\n",
       " 'yeah',\n",
       " 'said']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If more than half of the comedians have it as a top word, exclude it from the list\n",
    "add_stop_words = [word for word, count in Counter(words).most_common() if count > 6]\n",
    "add_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's update our document-term matrix with the new list of stop words\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Read in cleaned data\n",
    "data_clean = pd.read_pickle('data_clean.pkl')\n",
    "\n",
    "# Add new stop words\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate document-term matrix\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "data_cv = cv.fit_transform(data_clean.transcript)\n",
    "data_stop = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_stop.index = data_clean.index\n",
    "\n",
    "# Pickle it for later use\n",
    "import pickle\n",
    "pickle.dump(cv, open(\"cv_stop.pkl\", \"wb\"))\n",
    "data_stop.to_pickle(\"dtm_stop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some word clouds!\n",
    "# Terminal / Anaconda Prompt: conda install -c conda-forge wordcloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wc = WordCloud(stopwords=stop_words, background_color=\"white\", colormap=\"Dark2\",\n",
    "               max_font_size=150, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ali</th>\n",
       "      <th>anthony</th>\n",
       "      <th>bill</th>\n",
       "      <th>bo</th>\n",
       "      <th>dave</th>\n",
       "      <th>hasan</th>\n",
       "      <th>jim</th>\n",
       "      <th>joe</th>\n",
       "      <th>john</th>\n",
       "      <th>louis</th>\n",
       "      <th>mike</th>\n",
       "      <th>ricky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaaaah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaahhhhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaauuugghhhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaahhhhh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaah</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombie</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombies</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoning</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>éclair</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7484 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ali  anthony  bill  bo  dave  hasan  jim  joe  john  louis  \\\n",
       "aaaaah              0        0     1   0     0      0    0    0     0      0   \n",
       "aaaaahhhhhhh        0        0     0   1     0      0    0    0     0      0   \n",
       "aaaaauuugghhhhhh    0        0     0   1     0      0    0    0     0      0   \n",
       "aaaahhhhh           0        0     0   1     0      0    0    0     0      0   \n",
       "aaah                0        0     0   0     1      0    0    0     0      0   \n",
       "...               ...      ...   ...  ..   ...    ...  ...  ...   ...    ...   \n",
       "zombie              1        0     1   0     0      0    0    0     0      0   \n",
       "zombies             0        0     1   0     0      0    0    0     0      0   \n",
       "zoning              0        0     1   0     0      0    0    0     0      0   \n",
       "zoo                 0        0     0   0     0      0    0    0     0      0   \n",
       "éclair              0        0     0   0     0      0    0    0     1      0   \n",
       "\n",
       "                  mike  ricky  \n",
       "aaaaah               0      0  \n",
       "aaaaahhhhhhh         0      0  \n",
       "aaaaauuugghhhhhh     0      0  \n",
       "aaaahhhhh            0      0  \n",
       "aaah                 0      0  \n",
       "...                ...    ...  \n",
       "zombie               0      0  \n",
       "zombies              0      0  \n",
       "zoning               0      0  \n",
       "zoo                  0      1  \n",
       "éclair               0      0  \n",
       "\n",
       "[7484 rows x 12 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the output dimensions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 6]\n",
    "\n",
    "full_names = ['Ali Wong', 'Anthony Jeselnik', 'Bill Burr', 'Bo Burnham', 'Dave Chappelle', 'Hasan Minhaj',\n",
    "              'Jim Jefferies', 'Joe Rogan', 'John Mulaney', 'Louis C.K.', 'Mike Birbiglia', 'Ricky Gervais']\n",
    "\n",
    "# Create subplots for each comedian\n",
    "for index, comedian in enumerate(data.columns):\n",
    "    wc.generate(data_clean.transcript[comedian])\n",
    "    \n",
    "    plt.subplot(3, 4, index+1)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(full_names[index])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ali Wong says the s-word a lot and talks about her husband. I guess that's funny to me.\n",
    "* A lot of people use the F-word. Let's dig into that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of unique words that each comedian uses\n",
    "\n",
    "# Identify the non-zero items in the document-term matrix, meaning that the word occurs at least once\n",
    "unique_list = []\n",
    "for comedian in data.columns:\n",
    "    uniques = data[comedian].to_numpy().nonzero()[0].size\n",
    "    unique_list.append(uniques)\n",
    "\n",
    "# Create a new dataframe that contains this unique word count\n",
    "data_words = pd.DataFrame(list(zip(full_names, unique_list)), columns=['comedian', 'unique_words'])\n",
    "data_unique_sort = data_words.sort_values(by='unique_words')\n",
    "data_unique_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the words per minute of each comedian\n",
    "\n",
    "# Find the total number of words that a comedian uses\n",
    "total_list = []\n",
    "for comedian in data.columns:\n",
    "    totals = sum(data[comedian])\n",
    "    total_list.append(totals)\n",
    "    \n",
    "# Comedy special run times from IMDB, in minutes\n",
    "run_times = [60, 59, 80, 60, 67, 73, 77, 63, 62, 58, 76, 79]\n",
    "\n",
    "# Let's add some columns to our dataframe\n",
    "data_words['total_words'] = total_list\n",
    "data_words['run_times'] = run_times\n",
    "data_words['words_per_minute'] = data_words['total_words'] / data_words['run_times']\n",
    "\n",
    "# Sort the dataframe by words per minute to see who talks the slowest and fastest\n",
    "data_wpm_sort = data_words.sort_values(by='words_per_minute')\n",
    "data_wpm_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot our findings\n",
    "import numpy as np\n",
    "\n",
    "y_pos = np.arange(len(data_words))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(y_pos, data_unique_sort.unique_words, align='center')\n",
    "plt.yticks(y_pos, data_unique_sort.comedian)\n",
    "plt.title('Number of Unique Words', fontsize=20)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(y_pos, data_wpm_sort.words_per_minute, align='center')\n",
    "plt.yticks(y_pos, data_wpm_sort.comedian)\n",
    "plt.title('Number of Words Per Minute', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Vocabulary**\n",
    "   * Ricky Gervais (British comedy) and Bill Burr (podcast host) use a lot of words in their comedy\n",
    "   * Louis C.K. (self-depricating comedy) and Anthony Jeselnik (dark humor) have a smaller vocabulary\n",
    "\n",
    "\n",
    "* **Talking Speed**\n",
    "   * Joe Rogan (blue comedy) and Bill Burr (podcast host) talk fast\n",
    "   * Bo Burnham (musical comedy) and Anthony Jeselnik (dark humor) talk slow\n",
    "   \n",
    "Ali Wong is somewhere in the middle in both cases. Nothing too interesting here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amount of Profanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earlier I said we'd revisit profanity. Let's take a look at the most common words again.\n",
    "Counter(words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's isolate just these bad words\n",
    "data_bad_words = data.transpose()[['fucking', 'fuck', 'shit']]\n",
    "data_profanity = pd.concat([data_bad_words.fucking + data_bad_words.fuck, data_bad_words.shit], axis=1)\n",
    "data_profanity.columns = ['f_word', 's_word']\n",
    "data_profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a scatter plot of our findings\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "for i, comedian in enumerate(data_profanity.index):\n",
    "    x = data_profanity.f_word.loc[comedian]\n",
    "    y = data_profanity.s_word.loc[comedian]\n",
    "    plt.scatter(x, y, color='blue')\n",
    "    plt.text(x+0.5, y+0.5, full_names[i], fontsize=10)\n",
    "    plt.xlim(-5, 155) \n",
    "    \n",
    "plt.title('Number of Bad Words Used in Routine', fontsize=20)\n",
    "plt.xlabel('Number of F Bombs', fontsize=15)\n",
    "plt.ylabel('Number of S Words', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Averaging 2 F-Bombs Per Minute!** - I don't like too much swearing, especially the f-word, which is probably why I've never heard of Bill Bur, Joe Rogan and Jim Jefferies.\n",
    "* **Clean Humor** - It looks like profanity might be a good predictor of the type of comedy I like. Besides Ali Wong, my two other favorite comedians in this group are John Mulaney and Mike Birbiglia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Side Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was our goal for the EDA portion of our journey? **To be able to take an initial look at our data and see if the results of some basic analysis made sense.**\n",
    "\n",
    "My conclusion - yes, it does, for a first pass. There are definitely some things that could be better cleaned up, such as adding more stop words or including bi-grams. But we can save that for another day. The results, especially the profanity findings, are interesting and make general sense, so we're going to move on.\n",
    "\n",
    "As a reminder, the data science process is an interative one. It's better to see some non-perfect but acceptable results to help you quickly decide whether your project is a dud or not, instead of having analysis paralysis and never delivering anything.\n",
    "\n",
    "**Alice's data science (and life) motto: Let go of perfectionism!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Additional Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What other word counts do you think would be interesting to compare instead of the f-word and s-word? Create a scatter plot comparing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
